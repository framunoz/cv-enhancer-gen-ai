{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351bb3c4",
   "metadata": {},
   "source": [
    "# CV Enhancer\n",
    "\n",
    "El objetivo es crear un agente que ayude a mejorar un currículum vitae (CV) agregando y enfocando las experiencias laborales y habilidades relevantes para un puesto de trabajo específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a25204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemini(model='gemini-2.5-flash-lite', speech_config=None, retry_options=HttpRetryOptions(\n",
       "  attempts=5,\n",
       "  exp_base=7.0,\n",
       "  http_status_codes=[\n",
       "    429,\n",
       "    500,\n",
       "    503,\n",
       "    504,\n",
       "  ],\n",
       "  initial_delay=1.0\n",
       "))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.adk.models.google_llm import Gemini\n",
    "from google.genai import types\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "\n",
    "class CvSaverConfig:\n",
    "\n",
    "    job_offer_summarizer_model: Gemini = Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    )\n",
    "\n",
    "    writer_model: Gemini = Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    )\n",
    "\n",
    "\n",
    "config = CvSaverConfig()\n",
    "\n",
    "config.job_offer_summarizer_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5719d",
   "metadata": {},
   "source": [
    "## Job Summarizer\n",
    "\n",
    "Since the first input is a job offer, a model is needed to summarize the job offer in order to extract the key points. This will help to avoid spending too many tokens when delegating the task of improving the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c75935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobOfferSummarized(job_description='Develop and maintain web applications.', requirements=['Python', 'Django', 'REST APIs'], tech_stack=['AWS', 'Docker', 'PostgreSQL'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class JobOfferSummarized(BaseModel):\n",
    "    job_description: str = Field(..., description=\"Concise description of the job\",)\n",
    "    requirements: list[str] = Field(..., description=\"Key requirements listed clearly\",)\n",
    "    tech_stack: list[str] = Field(..., description=\"Technologies and tools mentioned\",)\n",
    "\n",
    "\n",
    "    __EXAMPLE__ = {\n",
    "        \"job_description\": \"Develop and maintain web applications.\",\n",
    "        \"requirements\": [\"Python\", \"Django\", \"REST APIs\"],\n",
    "        \"tech_stack\": [\"AWS\", \"Docker\", \"PostgreSQL\"],\n",
    "    }\n",
    "\n",
    "assert JobOfferSummarized(  # noqa: S101\n",
    "    **JobOfferSummarized.__EXAMPLE__\n",
    "), \"Example does not conform to schema\"\n",
    "\n",
    "job_offer_summ = JobOfferSummarized(**JobOfferSummarized.__EXAMPLE__)\n",
    "\n",
    "job_offer_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7872ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.genai import types\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "You are a Job Offer Summarizer. Your only task is to read the provided job offer\n",
    "and extract the key information such as the description, requirements, stack\n",
    "and provide a concise summary. Do not add any additional information\n",
    "(such as benefits, the title, the company...) or opinions.\n",
    "\n",
    "The output must be only the summarized job offer without any additional\n",
    "commentary.\n",
    "\n",
    "Here is an example of the output format:\n",
    "---\n",
    "{json.dumps(JobOfferSummarized.__EXAMPLE__, indent=2)}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "job_offer_summarizer_agent = Agent(\n",
    "    name=\"JobOfferSummarizerAgent\",\n",
    "    model=config.job_offer_summarizer_model,\n",
    "    description=(\n",
    "        \"An agent that summarizes job offers by extracting key information and\"\n",
    "        \" presenting it clearly to assist job seekers in understanding\"\n",
    "        \" the opportunities.\"\n",
    "    ),\n",
    "    instruction=PROMPT,\n",
    "    output_key=\"summarized_job_offer\",\n",
    "    output_schema=JobOfferSummarized,\n",
    ")\n",
    "\n",
    "# Expose the agent for external use\n",
    "root_agent = job_offer_summarizer_agent\n",
    "\n",
    "print(\"✅ Root Agent defined.\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16bae36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Runner created.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "\n",
    "print(\"✅ Runner created.\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687d2354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > \n",
      "NeuralWorks es una compañía de alto crecimiento fundada hace aproximadamente 4 años. Estamos trabajando a toda máquina en cosas que darán que hablar.\n",
      "\n",
      "Somos un equipo donde se unen la creatividad, curiosidad y la pasión por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detección de caras, un sensor de posición bluetooth, la recreación de un espacio acústico usando finite impulse response.\n",
      "\n",
      "Estos son solo algunos de los desafíos, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.\n",
      "\n",
      "Trabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, diseñamos y creamos productos digitales capaces de cautivar y crear impacto.\n",
      "\n",
      " Descripción del trabajo\n",
      "\n",
      "El equipo de Analytics trabaja en diferentes proyectos que combinan volúmenes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visión por computador.\n",
      "\n",
      "Como Data Scientist, trabajarás en conjunto con Machine Learning Engineers,Translators, Data Engineers entre otros perfiles, construyendo productos basados en datos que permitan llevar las prácticas de negocio al siguiente nivel.\n",
      "\n",
      "El equipo de Analítica no opera como un equipo de Research separado, sino que está profundamente integrado con nuestros clientes y sus unidades de negocio, esto permite un feedback loop rápido para iterar, corregir y perfeccionar para finalmente conseguir el impacto de negocio.\n",
      "\n",
      "En cualquier proyecto que trabajes, esperamos que tengas un gran espíritu de colaboración, una pasión por la innovación y el código y una mentalidad de automatización antes que procesos manuales.\n",
      "\n",
      "Tu trabajo variará de proyecto a proyecto, pero siguiendo una estructura similar:\n",
      "\n",
      "Identificar problemas de analítica que tengan un mayor impacto para la organización.\n",
      "Familiarizarte con el problema junto a expertos, recabar información, opiniones y facts\n",
      "Investigar las mejores prácticas de la industria.\n",
      "Definir hipótesis de trabajo y approach técnico para resolver el problema, incluyendo el set de datos a utilizar, variables, periodo de tiempo, etc.\n",
      "Recopilar datasets estructurados y no estructurados desde múltiples fuentes.\n",
      "Realizar limpieza de datos y validar correctitud.\n",
      "Aplicar modelos y algoritmos para minería de datos.\n",
      "Analizar resultados e identificar patrones y tendencias.\n",
      "Diseñar junto a Machine Learning Engineers soluciones que permitan capturar oportunidades.\n",
      "Comunicar los resultados y discutirlos junto a expertos o tomadores de decisiones.\n",
      "Algunos proyectos pueden incluir desafíos complejos en visión por computador.\n",
      "\n",
      " Calificaciones clave\n",
      "\n",
      "Estudios de Ingeniería Civil en Computación o similar.\n",
      "Experiencia previa en roles de Data Scientist, Data Engineer o similar.\n",
      "Experiencia con Python.\n",
      "Entendimiento de estructuras de datos con habilidades analíticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida la optimización de consultas.\n",
      "Entendimiento de flujo de vida completo modelos de Machine Learning y productos de datos.\n",
      "Habilidades analíticas, de diseño y resolución de problemas.\n",
      "Habilidades de colaboración y comunicación.\n",
      "Buen manejo comunicacional y skills colaborativos.\n",
      "Buen manejo de inglés, sobre todo en lectura donde debes ser capaz de leer un paper, artículos o documentación de forma constante.\n",
      "\n",
      "¡En NeuralWorks nos importa la diversidad! Creemos firmemente en la creación de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.\n",
      "\n",
      "“Los hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres sólo si cumplen el 100%.” D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.\n",
      "\n",
      "Te invitamos a postular aunque no cumplas con todos los requisitos.\n",
      "\n",
      " Nice to have\n",
      "\n",
      "Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.\n",
      "Experiencia usando pipelines de CI/CD y Docker.\n",
      "Experiencia en visión por computador (Computer Vision), incluyendo uso de librerías como OpenCV, PyTorch/TensorFlow, YOLO, Detectron2 u otras.\n",
      "\n",
      " Beneficios\n",
      "\n",
      "MacBook Air M2 o similar (con opción de compra hiper conveniente)\n",
      "Bono por desempeño\n",
      "Bono de almuerzo mensual y almuerzo de equipo los viernes\n",
      "Seguro Complementario de salud y dental\n",
      "Horario flexible\n",
      "Flexibilidad entre oficina y home office\n",
      "Medio día libre el día de tu cumpleaños\n",
      "Financiamiento de certificaciones\n",
      "Inscripción en Coursera con plan de entrenamiento a medida\n",
      "Estacionamiento de bicicletas\n",
      "Programa de referidos\n",
      "Salida de “teambuilding” mensual\n",
      "    \n",
      "JobOfferSummarizerAgent > {\n",
      "  \"job_description\": \"Work on projects involving large data volumes and AI, such as predicting failures, optimizing pricing, personalizing customer experiences, and computer vision tasks. Collaborate with Machine Learning Engineers, Translators, and Data Engineers to build data-driven products. Deeply integrated with clients and business units for rapid feedback loops. Requires a collaborative spirit, passion for innovation, and automation mindset.\",\n",
      "  \"requirements\": [\n",
      "    \"Degree in Civil Engineering in Computing or similar.\",\n",
      "    \"Previous experience in Data Scientist, Data Engineer, or similar roles.\",\n",
      "    \"Experience with Python.\",\n",
      "    \"Understanding of data structures with analytical skills for unstructured datasets.\",\n",
      "    \"Advanced SQL knowledge, including query optimization.\",\n",
      "    \"Understanding of the full lifecycle of Machine Learning models and data products.\",\n",
      "    \"Analytical, design, and problem-solving skills.\",\n",
      "    \"Collaboration and communication skills.\",\n",
      "    \"Good English proficiency, especially for reading technical papers and documentation.\"\n",
      "  ],\n",
      "  \"tech_stack\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"GCP\",\n",
      "    \"AWS\",\n",
      "    \"Azure\",\n",
      "    \"Docker\",\n",
      "    \"CI/CD\",\n",
      "    \"Computer Vision\",\n",
      "    \"OpenCV\",\n",
      "    \"PyTorch\",\n",
      "    \"TensorFlow\",\n",
      "    \"YOLO\",\n",
      "    \"Detectron2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\n",
    "    \"\"\"\n",
    "NeuralWorks es una compañía de alto crecimiento fundada hace aproximadamente 4 años. Estamos trabajando a toda máquina en cosas que darán que hablar.\n",
    "\n",
    "Somos un equipo donde se unen la creatividad, curiosidad y la pasión por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detección de caras, un sensor de posición bluetooth, la recreación de un espacio acústico usando finite impulse response.\n",
    "\n",
    "Estos son solo algunos de los desafíos, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.\n",
    "\n",
    "Trabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, diseñamos y creamos productos digitales capaces de cautivar y crear impacto.\n",
    "\n",
    " Descripción del trabajo\n",
    "\n",
    "El equipo de Analytics trabaja en diferentes proyectos que combinan volúmenes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visión por computador.\n",
    "\n",
    "Como Data Scientist, trabajarás en conjunto con Machine Learning Engineers,Translators, Data Engineers entre otros perfiles, construyendo productos basados en datos que permitan llevar las prácticas de negocio al siguiente nivel.\n",
    "\n",
    "El equipo de Analítica no opera como un equipo de Research separado, sino que está profundamente integrado con nuestros clientes y sus unidades de negocio, esto permite un feedback loop rápido para iterar, corregir y perfeccionar para finalmente conseguir el impacto de negocio.\n",
    "\n",
    "En cualquier proyecto que trabajes, esperamos que tengas un gran espíritu de colaboración, una pasión por la innovación y el código y una mentalidad de automatización antes que procesos manuales.\n",
    "\n",
    "Tu trabajo variará de proyecto a proyecto, pero siguiendo una estructura similar:\n",
    "\n",
    "Identificar problemas de analítica que tengan un mayor impacto para la organización.\n",
    "Familiarizarte con el problema junto a expertos, recabar información, opiniones y facts\n",
    "Investigar las mejores prácticas de la industria.\n",
    "Definir hipótesis de trabajo y approach técnico para resolver el problema, incluyendo el set de datos a utilizar, variables, periodo de tiempo, etc.\n",
    "Recopilar datasets estructurados y no estructurados desde múltiples fuentes.\n",
    "Realizar limpieza de datos y validar correctitud.\n",
    "Aplicar modelos y algoritmos para minería de datos.\n",
    "Analizar resultados e identificar patrones y tendencias.\n",
    "Diseñar junto a Machine Learning Engineers soluciones que permitan capturar oportunidades.\n",
    "Comunicar los resultados y discutirlos junto a expertos o tomadores de decisiones.\n",
    "Algunos proyectos pueden incluir desafíos complejos en visión por computador.\n",
    "\n",
    " Calificaciones clave\n",
    "\n",
    "Estudios de Ingeniería Civil en Computación o similar.\n",
    "Experiencia previa en roles de Data Scientist, Data Engineer o similar.\n",
    "Experiencia con Python.\n",
    "Entendimiento de estructuras de datos con habilidades analíticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida la optimización de consultas.\n",
    "Entendimiento de flujo de vida completo modelos de Machine Learning y productos de datos.\n",
    "Habilidades analíticas, de diseño y resolución de problemas.\n",
    "Habilidades de colaboración y comunicación.\n",
    "Buen manejo comunicacional y skills colaborativos.\n",
    "Buen manejo de inglés, sobre todo en lectura donde debes ser capaz de leer un paper, artículos o documentación de forma constante.\n",
    "\n",
    "¡En NeuralWorks nos importa la diversidad! Creemos firmemente en la creación de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.\n",
    "\n",
    "“Los hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres sólo si cumplen el 100%.” D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.\n",
    "\n",
    "Te invitamos a postular aunque no cumplas con todos los requisitos.\n",
    "\n",
    " Nice to have\n",
    "\n",
    "Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.\n",
    "Experiencia usando pipelines de CI/CD y Docker.\n",
    "Experiencia en visión por computador (Computer Vision), incluyendo uso de librerías como OpenCV, PyTorch/TensorFlow, YOLO, Detectron2 u otras.\n",
    "\n",
    " Beneficios\n",
    "\n",
    "MacBook Air M2 o similar (con opción de compra hiper conveniente)\n",
    "Bono por desempeño\n",
    "Bono de almuerzo mensual y almuerzo de equipo los viernes\n",
    "Seguro Complementario de salud y dental\n",
    "Horario flexible\n",
    "Flexibilidad entre oficina y home office\n",
    "Medio día libre el día de tu cumpleaños\n",
    "Financiamiento de certificaciones\n",
    "Inscripción en Coursera con plan de entrenamiento a medida\n",
    "Estacionamiento de bicicletas\n",
    "Programa de referidos\n",
    "Salida de “teambuilding” mensual\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_simiarity(\n",
    "    set1: set[str], set2: set[str], reference_set: set[str] | None = None\n",
    ") -> float:\n",
    "    if reference_set is None:\n",
    "        reference_set = set1.union(set2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(reference_set)\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-enhancer-gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
