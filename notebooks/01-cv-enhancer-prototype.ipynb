{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CV Enhancer Prototype\n",
    "\n",
    "This notebook develops a prototype agent that enhances work experiences in a resume using generative language models.\n",
    "\n",
    "To use this notebook, make sure you have the necessary dependencies installed and configure the appropriate environment variables to access generative language model services.\n",
    "\n",
    "You need to install the following libraries if you don't already have them (use uv to install dependencies):\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Additionally, you need to authenticate with the Gemini API. To do this, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys) and add the environment variable `GOOGLE_API_KEY` to a `.env` file in the root of your project. Ensure that the `.env` file contains the following line:\n",
    "\n",
    "```\n",
    "GOOGLE_API_KEY=tu_api_key_aqui\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3c2ab",
   "metadata": {},
   "source": [
    "## 1. âš™ï¸ Initial Configuration and Setup\n",
    "This section covers the environment preparation, constant definitions, and the critical step of initializing the core components of the Agent system: the Large Language Models (LLMs) and their corresponding configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Environment Initialization and Global Constraints\n",
    "\n",
    "This block initializes the project environment and defines global constants that govern the agent's behavior and operational scope.\n",
    "\n",
    "* **Environment Loading**: Securely loads environment variables (e.g., API keys) using `dotenv`. This ensures separation of credentials from the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "DOTENV_FILE = Path(\"../.env\")\n",
    "load_dotenv(DOTENV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e19c",
   "metadata": {},
   "source": [
    "### Design Constraints & Scope Configuration\n",
    "\n",
    "Defines the operational boundaries of the prototype to manage computational costs and latency. \n",
    "\n",
    "* **`EXPERIENCE_LIMITS` (Architectural Design)**: Defines a dictionary to specify the **maximum number of experiences to enhance per category** (e.g., `work=1`). This limits the scope of the RAG and enhancement process, prioritizing the most recent or relevant experiences and optimizing API usage.\n",
    "* **`MAX_REFINEMENT_ITERATIONS`**: Sets the cap for the number of internal loops the **Refinement Agent** will run when seeking improvement feedback from the **Critic Agent**. This directly controls the trade-off between output quality and processing cost/latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "\n",
    "\n",
    "class ExperienceLimits(t.TypedDict, total=False):\n",
    "    \"\"\"Limits for the number of experiences to enhance in each category.\"\"\"\n",
    "\n",
    "    work: int\n",
    "    volunteer: int\n",
    "    certificates: int\n",
    "    projects: int\n",
    "    skills: int\n",
    "    interests: int\n",
    "\n",
    "\n",
    "EXPERIENCE_LIMITS = ExperienceLimits(\n",
    "    work=1,\n",
    ")\n",
    "\n",
    "MAX_REFINEMENT_ITERATIONS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f4bde",
   "metadata": {},
   "source": [
    "### ðŸ“‚ Input Data Definition\n",
    "\n",
    "This cell defines the file path for the candidate's CV and imports the target job description text, which serves as the primary input for the entire enhancement pipeline.\n",
    "\n",
    "* **`JSON_RESUME_FILE`**: Path to the candidate's original CV, formatted in the `JsonResume` standard.\n",
    "* **`JOB_OFFER_TEXT`**: The raw text of the job advertisement. This text will be processed by the first agent in the chain (`JobOfferAnalyzerAgent`) to extract actionable requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_RESUME_FILE = Path(\"../data/json_resume_example.json\")\n",
    "\n",
    "# Offer obtained from: https://www.linkedin.com/jobs/collections/?currentJobId=4324487265\n",
    "JOB_OFFER_TEXT = \"\"\"\n",
    "We are still looking for talentâ€¦ and we would love for you to join our team!\n",
    "\n",
    "For over 25 years, UST has worked alongside the world's best companies to make a real impact through business transformation. Driven by technology, inspired by people, and guided by our purpose, UST supports clients from design to implementation. Together, with more than 30,000 employees in 30 countries, we build to create limitless impact, reaching billions of lives in the process.\n",
    "\n",
    "\n",
    "We are looking for an AI Engineer, to join a strategic project supporting data platform modernization.\n",
    "\n",
    "\n",
    "\n",
    "UST is looking for a candidate with strong Python expertise, proven experience building applications using LLMs, and hands-on exposure to agentic AI frameworks.\n",
    "\n",
    "\n",
    "\n",
    "What We're Looking For:\n",
    "\n",
    "Experience: 6 to 8 years of professional experience.\n",
    "Language: Advanced English B2 - C1\n",
    "Strong programming expertise in Python.\n",
    "Proven experience building applications using any LLMs.\n",
    "1 to 2 years of hands-on experience with agentic AI frameworks.\n",
    "Familiarity with cloud platforms.\n",
    "\n",
    "\n",
    "Why Join Us:\n",
    "\n",
    "Work in a remote and global environment\n",
    "Be part of a mission-critical application team\n",
    "Work in a supportive, collaborative environment\n",
    "Opportunity to mentor others and influence product direction\n",
    "Gain exposure to cloud migration and modern development practices\n",
    "\n",
    "\n",
    "UST is waiting for you!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7577043",
   "metadata": {},
   "source": [
    "### ðŸ§  Model Configuration and LLM Strategy\n",
    "\n",
    "This section defines the retry policy and initializes the specific **Gemini LLM models** used by each component of the multi-agent system. This demonstrates a **strategic model selection** based on the task complexity.\n",
    "\n",
    "* **`retry_config`**: Defines robust HTTP retry options (e.g., retrying on status codes 429, 503) to ensure resilience against temporary API throttling or server errors.\n",
    "* **`CvSaverConfig` (Design Pattern)**: A dataclass used to encapsulate and manage the different LLM instances required by the various agents, promoting **clean architecture** and easy configuration swap.\n",
    "* **Model Selection Strategy**:\n",
    "    * **`gemini-2.5-pro` (Critic Agent)**: The Pro model is selected for the `critic_model` due to its superior reasoning and analytical capabilities, which are essential for providing high-quality, constructive feedback during the refinement loop.\n",
    "    * **`gemini-2.5-flash-preview-09-2025` (Summarizer & Enhancer)**: The Flash model is used for data extraction and initial content generation tasks where speed and cost efficiency are prioritized.\n",
    "    * **`gemini-2.5-flash-lite` (Query Builder)**: The lightest model is used for the `query_builder_model` as the task involves concise output generation, maximizing cost savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.genai import types\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=10,  # Maximum retry attempts\n",
    "    initial_delay=1,\n",
    "    max_delay=60,\n",
    "    exp_base=3,  # Delay multiplier\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CvSaverConfig:\n",
    "    job_offer_summarizer_model: Gemini\n",
    "    experience_enhancement_model: Gemini\n",
    "    critic_model: Gemini\n",
    "    query_builder_model: Gemini\n",
    "\n",
    "\n",
    "# See more models at https://ai.google.dev/gemini-api/docs/pricing\n",
    "config = CvSaverConfig(\n",
    "    job_offer_summarizer_model=Gemini(\n",
    "        model=\"gemini-2.5-flash-preview-09-2025\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    experience_enhancement_model=Gemini(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    critic_model=Gemini(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    query_builder_model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbea491",
   "metadata": {},
   "source": [
    "## 2. ðŸ“ Data Handling and Preprocessing\n",
    "\n",
    "This section covers the loading, validation, and preparation of the candidate's CV data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1365bd",
   "metadata": {},
   "source": [
    "### ðŸ’¾ CV Loading, Validation, and Display\n",
    "\n",
    "These cells implement the loading of the JSON CV file and its validation using **Pydantic schemas** (`JsonResume`), ensuring data integrity and structure before it is consumed by the RAG system.\n",
    "\n",
    "* **`get_json_resume()`**: Loads the raw JSON and uses `JsonResume.model_validate_json()` to strictly enforce the expected CV data structure (a core use of Pydantic).\n",
    "* **Display/Formatting**: Iterates over the validated resume object, displaying the distinct experiences in a human-readable Markdown format using the custom `format()` method. This step is crucial for verifying the input data's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from cv_enhancer.schemas import JsonResume\n",
    "\n",
    "\n",
    "def get_json_resume() -> JsonResume:\n",
    "    \"\"\"Load a JSON resume from a file and validate it against the JsonResume schema.\n",
    "\n",
    "    Returns:\n",
    "        JsonResume: The validated JSON resume object.\n",
    "    \"\"\"\n",
    "    with Path(JSON_RESUME_FILE).open(encoding=\"utf-8\") as f:\n",
    "        json_resume = JsonResume.model_validate_json(f.read())\n",
    "\n",
    "    return json_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "json_resume = get_json_resume()\n",
    "\n",
    "rprint(json_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display as ip_display\n",
    "\n",
    "from cv_enhancer.schemas.json_resume._abc import JsonResumeFormattableBaseModel\n",
    "\n",
    "experencies: list[JsonResumeFormattableBaseModel] = []\n",
    "different_experencies = {}\n",
    "for exp in json_resume.iter_over_formatables():\n",
    "    experencies.append(exp)\n",
    "    different_experencies[type(exp)] = exp\n",
    "\n",
    "for exp in different_experencies.values():\n",
    "    ip_display(Markdown(exp.format()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8ad9e",
   "metadata": {},
   "source": [
    "### ðŸ”¢ RAG Architecture: Custom Gemini Embedding Function\n",
    "\n",
    "This is a critical architectural cell defining the **RAG (Retrieval-Augmented Generation)** component. It implements a custom `GeminiEmbeddingFunction` for ChromaDB, which is necessary to align the embedding generation with the Google AI SDK best practices.\n",
    "\n",
    "* **Retry Decorator (`@retry.Retry`)**: Applies resilience to the embedding call, handling potential API errors (429/503) specifically.\n",
    "* **Task Type (Design)**: Explicitly sets the `task_type` (`RETRIEVAL_DOCUMENT` vs. `RETRIEVAL_QUERY`) based on whether the input is for indexing (the CV) or searching (the query). This ensures **optimal embedding quality** for the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google import genai\n",
    "from google.api_core import retry\n",
    "from google.genai import types\n",
    "from google.genai.errors import APIError\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "def is_retriable(e):\n",
    "    return isinstance(e, APIError) and e.code in {429, 503}\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    EMBEDDING_MODEL = \"models/text-embedding-004\"\n",
    "    OUTPUT_DIM = 768\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        document_mode: bool = True,\n",
    "        embedding_model: str | None = None,\n",
    "        output_dim: int | None = None,\n",
    "    ):\n",
    "        self.document_mode = document_mode\n",
    "        self.embedding_model = embedding_model\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    @property\n",
    "    def task_type(self) -> str:\n",
    "        return \"RETRIEVAL_DOCUMENT\" if self.document_mode else \"RETRIEVAL_QUERY\"\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    @t.override\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        response = client.models.embed_content(\n",
    "            model=self.embedding_model or self.EMBEDDING_MODEL,\n",
    "            contents=input,  # type: ignore\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=self.task_type,\n",
    "                output_dimensionality=self.output_dim or self.OUTPUT_DIM,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff660e0",
   "metadata": {},
   "source": [
    "### ðŸ—ƒï¸ ChromaDB Initialization and RAG Tool Definition\n",
    "\n",
    "These cells initialize the Vector Database and define the core RAG function that acts as a **Tool** for the agent system.\n",
    "\n",
    "* **Database Creation**: Initializes the `chromadb.Client()` and creates/gets the `cv_embeddings_v3` collection, injecting the custom `embed_fn`.\n",
    "* **Indexing**: Adds all formatted experiences from the CV into the ChromaDB collection. Each experience's text is the `document`, and metadata (like `item_type`) is attached for filtering/categorization.\n",
    "* **`retrieve_experiences_by_query()` (Agent Tool)**: Defines the function that interfaces with the ChromaDB. This function is essential as it takes the LLM-generated query and returns the most semantically relevant experiences, forming the **Knowledge Base** for the enhancement agents. It manages the `document_mode` switch internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction(document_mode=True)\n",
    "\n",
    "DB_NAME = \"cv_embeddings_v3\"\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "db.add(\n",
    "    documents=[e.format() for e in experencies],\n",
    "    ids=[e.get_id() for e in experencies],\n",
    "    metadatas=[{\"item_type\": e.item_type} for e in experencies],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from chromadb.base_types import Metadata\n",
    "\n",
    "ValidExperienceKeys = t.Literal[\n",
    "    \"work\",\n",
    "    \"volunteer\",\n",
    "    \"certificates\",\n",
    "    \"projects\",\n",
    "    \"skills\",\n",
    "    \"interests\",\n",
    "]\n",
    "\n",
    "\n",
    "class ExperienceRetrieval(t.TypedDict):\n",
    "    exp_id: str\n",
    "    exp_type: ValidExperienceKeys\n",
    "    description: str\n",
    "    distance: float\n",
    "\n",
    "\n",
    "class ExperienceRetrievalResult(t.TypedDict, total=False):\n",
    "    status: str\n",
    "    retrieved_experiences: list[ExperienceRetrieval]\n",
    "    message: str\n",
    "\n",
    "\n",
    "def retrieve_experiences_by_query(\n",
    "    query: str,\n",
    "    n_results: int,\n",
    ") -> ExperienceRetrievalResult:\n",
    "    \"\"\"Retrieve experiences from the ChromaDB based on a query string.\n",
    "    The embedding function will be switched to query mode during this operation.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "        n_results (int): The number of top results to retrieve. If the value\n",
    "            is less than or equal to zero, all experiences will be retrieved.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, str]: A dictionary containing the status and retrieved experiences.\n",
    "\n",
    "    Example:\n",
    "        >>> retrieve_experiences_by_query(\n",
    "        ...     query=\"Python, SQL, Machine Learning\",\n",
    "        ...     n_results=2,\n",
    "        ... )\n",
    "        {\n",
    "            \"status\": \"success\",\n",
    "            \"retrieved_experiences\": [\n",
    "                {\n",
    "                    \"exp_id\": \"work_1\",\n",
    "                    \"description\": \"Developed data pipelines using Python and SQL...\",\n",
    "                    \"exp_type\": \"work\",\n",
    "                    \"distance\": 0.12345\n",
    "                },\n",
    "                {\n",
    "                    \"exp_id\": \"project_3\",\n",
    "                    \"description\": \"Implemented machine learning models using Python...\",\n",
    "                    \"exp_type\": \"project\",\n",
    "                    \"distance\": 0.23456\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Switch to query mode when generating embeddings.\n",
    "    embed_fn.document_mode = False\n",
    "\n",
    "    if db.count() == 0:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"The database is empty. No experiences to retrieve.\",\n",
    "        }\n",
    "\n",
    "    # Search the Chroma DB using the specified query.\n",
    "    if n_results <= 0:\n",
    "        n_results = db.count()\n",
    "\n",
    "    try:\n",
    "        result = db.query(query_texts=[query], n_results=n_results)\n",
    "\n",
    "        documents: list[str] = []\n",
    "        ids: list[str] = []\n",
    "        metadatas: list[Metadata] = []\n",
    "        distances: list[float] = []\n",
    "\n",
    "        if result[\"documents\"]:\n",
    "            documents = result[\"documents\"][0]\n",
    "\n",
    "        if result[\"ids\"]:\n",
    "            ids = result[\"ids\"][0]\n",
    "\n",
    "        if result[\"metadatas\"]:\n",
    "            metadatas = result[\"metadatas\"][0]\n",
    "\n",
    "        if result[\"distances\"]:\n",
    "            distances = result[\"distances\"][0]\n",
    "\n",
    "        retrived_experiences = [\n",
    "            ExperienceRetrieval(\n",
    "                exp_type=str(metadata[\"item_type\"]),  # type: ignore\n",
    "                description=passage,\n",
    "                exp_id=exp_id,\n",
    "                distance=distance,\n",
    "            )\n",
    "            for exp_id, passage, metadata, distance in zip(\n",
    "                ids, documents, metadatas, distances, strict=False\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"retrieved_experiences\": retrived_experiences,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": str(e),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418abac3",
   "metadata": {},
   "source": [
    "## 3. ðŸ¤– Agent Definition and Orchestration\n",
    "This is the core of the solution, defining the roles, prompts, and the overall sequential and parallel multi-agent flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754c1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14663faa",
   "metadata": {},
   "source": [
    "### 1. ðŸ“ Agent Chain Start: Job Offer Analyzer Agent\n",
    "\n",
    "This agent is the **entry point** for processing the job offer. Its primary role is **Data Extraction and Structuring**, converting unstructured job text into actionable, schema-compliant data.\n",
    "\n",
    "* **Pydantic Schema (`JobOfferSummarized`)**: Enforces a strict, structured output format for the job summary, ensuring downstream agents receive clean, typed input (requirements, tech stack).\n",
    "* **Agent Role (`Agent`)**: Defined using the Google AI SDK, with a clear `instruction` to be concise, accurate, and maintain the original language.\n",
    "* **`output_schema`**: The Pydantic schema is enforced here, making this a **Reliable Extractor Agent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class JobOfferSummarized(BaseModel):\n",
    "    job_description: str = Field(\n",
    "        ...,\n",
    "        description=\"Concise description of the job\",\n",
    "    )\n",
    "    requirements: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Key requirements listed clearly\",\n",
    "    )\n",
    "    tech_stack: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Technologies and tools mentioned\",\n",
    "    )\n",
    "\n",
    "    __EXAMPLE__ = {\n",
    "        \"job_description\": \"Develop and maintain web applications.\",\n",
    "        \"requirements\": [\"Python\", \"Django\", \"REST APIs\"],\n",
    "        \"tech_stack\": [\"AWS\", \"Docker\", \"PostgreSQL\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "You are a Job Offer Summarizer. Your only task is to read the provided job offer\n",
    "and extract the key information such as the description, requirements, stack\n",
    "and provide a concise summary. Do not add any additional information\n",
    "(such as benefits, the title, the company...) or opinions. Try to summarize\n",
    "in 300 words maximum.\n",
    "\n",
    "The output must be only the summarized job offer without any additional\n",
    "commentary.\n",
    "\n",
    "Try to be as specific as possible when extracting the tech stack.\n",
    "\n",
    "Here is an example of the output format:\n",
    "---\n",
    "{json.dumps(JobOfferSummarized.__EXAMPLE__, indent=2)}\n",
    "---\n",
    "\n",
    "You MUST RETURN the output in the EXACT FORMAT as shown above, without any additional text.\n",
    "\n",
    "Mantain the original language of the job offer.\n",
    "\"\"\"\n",
    "\n",
    "job_offer_analyzer_agent = Agent(\n",
    "    name=\"JobOfferAnalyzerAgent\",\n",
    "    model=config.job_offer_summarizer_model,\n",
    "    description=(\n",
    "        \"An agent that summarizes job offers by extracting key information and\"\n",
    "        \" presenting it clearly to assist job seekers in understanding\"\n",
    "        \" the opportunities.\"\n",
    "    ),\n",
    "    instruction=PROMPT,\n",
    "    output_key=\"summarized_job_offer\",\n",
    "    output_schema=JobOfferSummarized,\n",
    ")\n",
    "\n",
    "print(\"âœ… Job Offer Summarizer Agent defined.\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8a88c",
   "metadata": {},
   "source": [
    "### 2. ðŸ“ Agent Chain Step: Experience Query Builder Agent\n",
    "\n",
    "This agent's task is to translate the structured job requirements into an optimal, dense **search query string** for the ChromaDB vector store.\n",
    "\n",
    "* **Input**: `{{summarized_job_offer}}` (from the previous agent).\n",
    "* **Output**: The `search_query` string (e.g., \"Python, SQL, Machine Learning, Data Mining...\").\n",
    "* **Role**: It bridges the language model's comprehension capabilities (understanding job requirements) with the RAG system's vector retrieval mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_experiences_by_type(\n",
    "    experiences: list[ExperienceRetrieval],\n",
    "    limits: ExperienceLimits,\n",
    ") -> list[ExperienceRetrieval]:\n",
    "    \"\"\"Limit the number of experiences by type.\n",
    "\n",
    "    Args:\n",
    "        experiences (list[ExperienceRetrieval]): The list of experiences to limit.\n",
    "        limits (ExperienceLimits): The limits for each experience type.\n",
    "\n",
    "    Returns:\n",
    "        list[ExperienceRetrieval]: The limited list of experiences.\n",
    "    \"\"\"\n",
    "    from collections import Counter  # noqa: PLC0415\n",
    "\n",
    "    counts: Counter[str] = Counter()\n",
    "    limited_experiences: list[ExperienceRetrieval] = []\n",
    "\n",
    "    for exp in experiences:\n",
    "        exp_type: ValidExperienceKeys = exp[\"exp_type\"]  # type: ignore\n",
    "        if exp_type in limits and counts[exp_type] < limits[exp_type]:\n",
    "            limited_experiences.append(exp)\n",
    "            counts.update([exp_type])\n",
    "\n",
    "    return limited_experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe783ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "You are a Query Builder Agent. Your task is to construct a search query\n",
    "that will help retrieve relevant experiences from a resume database based\n",
    "on the provided job requirements and technology stack.\n",
    "\n",
    "Job offer summary:\n",
    "{{summarized_job_offer}}\n",
    "\n",
    "Please ensure that the query is tailored to the specific technologies\n",
    "and skills mentioned in the job description. Additionally, consider the\n",
    "candidate's experience level and relevant certifications.\n",
    "\n",
    "The output should be a concise search query string that effectively captures\n",
    "the key requirements and technologies needed for the job.\n",
    "\n",
    "Consider the following when building the query:\n",
    "- The database is a vector database containing experiences from resumes,\n",
    "    including work experience, volunteer work, certifications, projects,\n",
    "    skills, and interests.\n",
    "- The documents were stored using the mode `RETRIEVAL_DOCUMENT` of the\n",
    "    model `{GeminiEmbeddingFunction.EMBEDDING_MODEL}`.\n",
    "- The query will be of type `RETRIEVAL_QUERY` and should be compatible\n",
    "    with the same model.\n",
    "- It is not necessary to include the year of experience or seniority level\n",
    "    in the query.\n",
    "\"\"\"\n",
    "\n",
    "experience_query_builder_agent = Agent(\n",
    "    name=\"ExperienceQueryBuilderAgent\",\n",
    "    model=config.query_builder_model,\n",
    "    description=\"\"\"An agent that builds search queries to retrieve relevant experiences\n",
    "    from a resume database based on job requirements and technology stack.\"\"\",\n",
    "    instruction=PROMPT,\n",
    "    output_key=\"search_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a1dc",
   "metadata": {},
   "source": [
    "### 3. ðŸ“ Agent Chain Step: Custom Experience Retrieval Agent\n",
    "\n",
    "This custom agent (`BaseAgent` subclass) executes the RAG retrieval operation outside of a standard LLM call, ensuring that the process is efficient and integrated directly into the agent workflow.\n",
    "\n",
    "* **Custom Agent**: Subclassing `BaseAgent` is used because this agent executes a **Python Tool** (`retrieve_experiences_by_query`) rather than an LLM call.\n",
    "* **Input**: Retrieves the `search_query` from the session state (placed by the `ExperienceQueryBuilderAgent`).\n",
    "* **Output**: Saves the `retrieved_experiences` (filtered and limited by `EXPERIENCE_LIMITS`) into the session state for the next agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import BaseAgent\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.adk.events import Event\n",
    "\n",
    "\n",
    "class ExperienceRetrieverAgent(BaseAgent):\n",
    "    \"\"\"An agent that retrieves the most relevant experiences and saves them in the session state.\"\"\"\n",
    "\n",
    "    experience_limits: ExperienceLimits | None = None\n",
    "\n",
    "    @t.override\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> t.AsyncGenerator[Event]:\n",
    "        logging.info(f\"[{self.name}] Starting Experience Retrieval Agent\")\n",
    "\n",
    "        # Get the search query from the session state\n",
    "        query = ctx.session.state.get(\"search_query\", None)\n",
    "        if query is None:\n",
    "            logging.error(f\"[{self.name}] No search query found in session state.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve the experiences using the retrieve_experiences_by_query tool\n",
    "        #  from the session state\n",
    "        retrieved_exps_result = retrieve_experiences_by_query(query=query, n_results=0)\n",
    "\n",
    "        if retrieved_exps_result.get(\"status\") != \"success\":\n",
    "            logging.error(\n",
    "                f\"[{self.name}] Failed to retrieve experiences:\"\n",
    "                f\" {retrieved_exps_result.get('message')}\"\n",
    "            )\n",
    "            return\n",
    "        retrieved_exps = retrieved_exps_result[\"retrieved_experiences\"]\n",
    "\n",
    "        # Limit the number of experiences if limits are provided\n",
    "        if self.experience_limits:\n",
    "            retrieved_exps = limit_experiences_by_type(\n",
    "                retrieved_exps,\n",
    "                limits=self.experience_limits,\n",
    "            )\n",
    "\n",
    "        # Sort experiences by exp_id in descending order to display\n",
    "        #  the most recent ones first.\n",
    "        retrieved_exps.sort(key=lambda x: x[\"exp_id\"], reverse=True)\n",
    "\n",
    "        # Save the retrieved experiences in the session state\n",
    "        ctx.session.state[\"retrieved_experiences\"] = retrieved_exps\n",
    "\n",
    "        logging.info(\n",
    "            f\"[{self.name}] Retrieved {len(retrieved_exps)} experiences for\"\n",
    "            \" enhancement.\"\n",
    "        )\n",
    "        logging.debug(f\"[{self.name}] Experiences: {retrieved_exps}\")\n",
    "\n",
    "        yield Event(author=self.name)\n",
    "\n",
    "\n",
    "experience_retriever_agent = ExperienceRetrieverAgent(\n",
    "    name=\"ExperienceRetrieverAgent\",\n",
    "    experience_limits=EXPERIENCE_LIMITS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f4fcd",
   "metadata": {},
   "source": [
    "### ðŸ”„ Refinement Loop Architecture (Iterative Self-Correction)\n",
    "\n",
    "This core architectural pattern implements a **Refinement Loop** using the Google AI SDK's `LoopAgent`. This mechanism ensures **iterative self-correction** by engaging a dedicated **Critic Agent** to evaluate the initial experience enhancement draft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### ðŸ“¦ Enhancement Output Schemas (Pydantic Design)\n",
    "\n",
    "This block defines the structured output schemas for the **Experience Enhancement Agents**. Using inheritance and specific fields for `work`, `projects`, and `skills`, it ensures the enhanced CV output is consistently formatted and validated.\n",
    "\n",
    "* **Structured Output**: Defines nested schemas (`SummaryKeywordsOutputSchema`, etc.) to enforce the required fields: `summary`, `highlights`, and `keywords`. This is critical for generating a CV that meets professional formatting standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordsOutputSchema(BaseModel):\n",
    "    keywords: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of relevant keywords or skills.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class SummaryKeywordsOutputSchema(KeywordsOutputSchema):\n",
    "    summary: str = Field(\n",
    "        ...,\n",
    "        description=\"A brief summary of the experience.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class SummaryHighlightsKeywordsOutputSchema(SummaryKeywordsOutputSchema):\n",
    "    highlights: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Key achievements or highlights of the experience.\",\n",
    "    )\n",
    "\n",
    "\n",
    "OUTPUT_SCHEMAS = {\n",
    "    \"work\": SummaryHighlightsKeywordsOutputSchema,\n",
    "    \"volunteer\": SummaryHighlightsKeywordsOutputSchema,\n",
    "    \"certificates\": SummaryKeywordsOutputSchema,\n",
    "    \"projects\": SummaryHighlightsKeywordsOutputSchema,\n",
    "    \"skills\": KeywordsOutputSchema,\n",
    "    \"interests\": KeywordsOutputSchema,\n",
    "}\n",
    "\n",
    "\n",
    "EXAMPLES = {\n",
    "    \"work\": {\n",
    "        \"summary\": \"Descriptionâ€¦\",\n",
    "        \"highlights\": [\"Started the company\"],\n",
    "        \"keywords\": [\"leadership\", \"entrepreneurship\"],\n",
    "    },\n",
    "    \"volunteer\": {\n",
    "        \"summary\": \"Descriptionâ€¦\",\n",
    "        \"highlights\": [\"Volunteered at local shelter\"],\n",
    "        \"keywords\": [\"community\", \"helping others\"],\n",
    "    },\n",
    "    \"certificates\": {\n",
    "        \"summary\": \"Descriptionâ€¦\",\n",
    "        \"keywords\": [\"certification\", \"achievement\"],\n",
    "    },\n",
    "    \"projects\": {\n",
    "        \"summary\": \"Descriptionâ€¦\",\n",
    "        \"highlights\": [\"Developed a web app\"],\n",
    "        \"keywords\": [\"Python\", \"Django\", \"AWS\"],\n",
    "    },\n",
    "    \"skills\": {\n",
    "        \"keywords\": [\"Python\", \"Machine Learning\", \"Data Analysis\"],\n",
    "    },\n",
    "    \"interests\": {\n",
    "        \"keywords\": [\"hiking\", \"photography\", \"travel\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6f9c9",
   "metadata": {},
   "source": [
    "#### ðŸ’¬ Agent Prompt Templates (Behavior Definition)\n",
    "\n",
    "This cell defines the core instruction sets for the **Enhancement** and **Critic** agents, implementing the **Refinement Loop** strategy.\n",
    "\n",
    "* **`PROMPT_INITIAL_EXP_ENHANCEMENT`**: Sets the instructions for the first-pass enhancement, emphasizing alignment with the `{{summarized_job_offer}}` and adherence to the Pydantic output format.\n",
    "* **`PROMPT_CRITIC` (Refinement Core)**: Defines the role of the critic. This agent performs a **Self-Correction/Iterative Improvement** function. Its output is concise (\"APPROVED\" or specific suggestions), designed to be used as input for the next agent iteration.\n",
    "* **`PROMPT_REFINER_EXP_ENHANCEMENT`**: Instructs the refining agent to incorporate the `{{critique_{agent_id}}}` feedback to improve the previous draft. The use of the `Original Experience Description` helps prevent \"hallucination\" by grounding the agent in the source text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_INITIAL_EXP_ENHANCEMENT = \"\"\"\n",
    "You are an experience enhancer. Your task is to improve the provided\n",
    "description of experience to better align it with the job posting summary.\n",
    "\n",
    "The main goal is to ensure that the experience description highlights\n",
    "the skills, technologies, and accomplishments that are most relevant to\n",
    "the job requirements and technology stack mentioned in the job posting.\n",
    "\n",
    "Job Posting Summary:\n",
    "{{summarized_job_offer}}\n",
    "\n",
    "Experience Description:\n",
    "{{experience_{agent_id}}}\n",
    "\n",
    "EXAMPLE:\n",
    "{example}\n",
    "\n",
    "YOU MUST RETURN the output in the EXACT FORMAT as shown in the example,\n",
    "without any additional text. NOT FOLLOWING THE FORMAT WILL CAUSE ERRORS.\n",
    "\n",
    "OUTPUT RULES:\n",
    "- The summary/description must be concise and focused on relevant skills\n",
    "    and accomplishments. Avoid unnecessary details. Try to keep it\n",
    "    in 1-2 sentences.\n",
    "- The highlights must be specific achievements or contributions,\n",
    "    quantifiable where possible. Try to include 2-3 highlights. Each highlight\n",
    "    should start with a strong action verb. Try to keep it in a sentence each.\n",
    "- The keywords must include relevant technologies, tools, and skills.\n",
    "    Try to include 3-5 keywords.\n",
    "- Do not invent details. Only use the information provided in the\n",
    "    experience description.\n",
    "- Mantain the original language of the experience description.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_CRITIC = \"\"\"\n",
    "You are a constructive critic. Your task is to review the provided\n",
    "draft of experience and provide feedback on how well it aligns with the\n",
    "job posting summary. Identify areas of improvement, suggest enhancements,\n",
    "and highlight any discrepancies between the draft and the job requirements.\n",
    "\n",
    "Job Posting Summary:\n",
    "{{summarized_job_offer}}\n",
    "\n",
    "Experience Draft:\n",
    "{{enhanced_experience_{agent_id}}}\n",
    "\n",
    "- If the draft is well-aligned, you MUST respond with the exact phrase: \"APPROVED\"\n",
    "- Otherwise, provide 1-3 specific, actionable suggestions for improvement,\n",
    "    of the draft to better align it with the job posting summary.\n",
    "- Be concise and specific in your feedback. Think about your suggestions\n",
    "    will be used for other agent to improve the experience draft.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_REFINER_EXP_ENHANCEMENT = \"\"\"\n",
    "You are an experience enhancer. Your task is to improve the provided\n",
    "description of experience to better align it with the job posting summary.\n",
    "The main goal is to ensure that the experience description highlights\n",
    "the skills, technologies, and accomplishments that are most relevant to\n",
    "the job requirements and technology stack mentioned in the job posting.\n",
    "\n",
    "Job Posting Summary:\n",
    "{{summarized_job_offer}}\n",
    "\n",
    "Original Experience Description:\n",
    "{{experience_{agent_id}}}\n",
    "\n",
    "Current Experience Draft:\n",
    "{{enhanced_experience_{agent_id}}}\n",
    "\n",
    "Critique Feedback:\n",
    "{{critique_{agent_id}}}\n",
    "\n",
    "EXAMPLE:\n",
    "{example}\n",
    "\n",
    "YOU MUST RETURN the output in the EXACT FORMAT as shown in the example,\n",
    "without any additional text. NOT FOLLOWING THE FORMAT WILL CAUSE ERRORS.\n",
    "\n",
    "- IF THE CRITIQUE IS \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n",
    "- OTHERWISE, use the critique feedback to make specific improvements\n",
    "    to the experience draft to better align it with the job posting summary.\n",
    "\n",
    "OUTPUT RULES:\n",
    "- The summary/description must be concise and focused on relevant skills\n",
    "    and accomplishments. Avoid unnecessary details. Try to keep it\n",
    "    in 1-2 sentences.\n",
    "- The highlights must be specific achievements or contributions,\n",
    "    quantifiable where possible. Try to include 2-3 highlights. Each highlight\n",
    "    should start with a strong action verb. Try to keep it in a sentence each.\n",
    "- The keywords must include relevant technologies, tools, and skills.\n",
    "    Try to include 3-5 keywords.\n",
    "- Do not invent details. Only use the information provided in the\n",
    "    experience description.\n",
    "- Mantain the original language of the experience description.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f21771",
   "metadata": {},
   "source": [
    "#### ðŸ”§ Refinement Loop Control Tool\n",
    "\n",
    "This simple function is defined as a **Tool** that the Refiner Agent can call. It serves as the explicit mechanism to **break the iterative refinement loop** when the Critic Agent responds with \"APPROVED.\" This is a key design pattern for controlled, tool-augmented loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_loop() -> dict[str, t.Any]:\n",
    "    \"\"\"\n",
    "    Call this function ONLY when the critique is 'APPROVED',\n",
    "    indicating the experience is finished and no more changes are needed.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"approved\",\n",
    "        \"message\": \"Experience approved. Exiting refinement loop.\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b56517",
   "metadata": {},
   "source": [
    "#### ðŸ­ Agent Factory: Multi-Agent Refinement System Creator\n",
    "\n",
    "This crucial function (`experience_refinament_agent_factory`) acts as a **factory** to dynamically create a complete **Sequential Agent** (which includes a **Loop Agent**) for *each individual experience* retrieved from the RAG step.\n",
    "\n",
    "* **Sequential Flow**: `InitialEnhancement -> LoopAgent`.\n",
    "* **Loop Agent**: Manages the iterative refinement flow: `Critic Agent -> Refiner Agent`.\n",
    "* **Meaningful Use of Agents**: This is the core architectural feature:\n",
    "    * **Specialization**: The system uses two specialized LLMs (Flash for generation, Pro for critique) within a single loop.\n",
    "    * **Self-Correction**: The Loop Agent implements a *self-correction feedback mechanism*, significantly improving output quality over a single-pass LLM call.\n",
    "    * **Tool Use**: The Refiner Agent is equipped with the `exit_loop` tool, allowing it to programmatically terminate the iteration when the goal is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from google.adk.agents import LoopAgent, SequentialAgent\n",
    "from google.adk.tools import FunctionTool\n",
    "\n",
    "\n",
    "def experience_refinament_agent_factory(\n",
    "    exp_type: ValidExperienceKeys, agent_id: str | None = None, max_iterations: int = 1\n",
    ") -> SequentialAgent:\n",
    "    # Use a unique agent ID if not provided\n",
    "    if agent_id is None:\n",
    "        agent_id = str(uuid.uuid4())[:8]\n",
    "\n",
    "    example = json.dumps(EXAMPLES[exp_type], indent=2)\n",
    "    schema_output = OUTPUT_SCHEMAS[exp_type]\n",
    "\n",
    "    initial_experience_draft_agent = Agent(\n",
    "        name=f\"InitialExperienceDraftAgent_{agent_id}\",\n",
    "        model=config.experience_enhancement_model,\n",
    "        description=(\n",
    "            \"An agent that enhances a first draft of experience\"\n",
    "            \" descriptions to better align them with job requirements and\"\n",
    "            \" technology stack.\"\n",
    "        ),\n",
    "        instruction=PROMPT_INITIAL_EXP_ENHANCEMENT.format(\n",
    "            agent_id=agent_id, example=example\n",
    "        ),\n",
    "        output_key=f\"enhanced_experience_{agent_id}\",\n",
    "        output_schema=schema_output,\n",
    "    )\n",
    "\n",
    "    experience_critique_agent = Agent(\n",
    "        name=f\"ExperienceCritiqueAgent_{agent_id}\",\n",
    "        model=config.critic_model,\n",
    "        description=(\n",
    "            \"An agent that critiques and provides feedback on a draft of experience.\"\n",
    "        ),\n",
    "        instruction=PROMPT_CRITIC.format(agent_id=agent_id),\n",
    "        output_key=f\"critique_{agent_id}\",\n",
    "    )\n",
    "\n",
    "    experience_refiner_agent = Agent(\n",
    "        name=f\"ExperienceRefinerAgent_{agent_id}\",\n",
    "        model=config.experience_enhancement_model,\n",
    "        description=(\n",
    "            \"An agent that enhances a draft of experience descriptions based on\"\n",
    "            \" feedback from a critic agent to better align them with job\"\n",
    "            \" requirements and technology stack.\"\n",
    "        ),\n",
    "        instruction=PROMPT_REFINER_EXP_ENHANCEMENT.format(\n",
    "            agent_id=agent_id, example=example\n",
    "        ),\n",
    "        output_key=f\"enhanced_experience_{agent_id}\",\n",
    "        output_schema=schema_output,\n",
    "        tools=[FunctionTool(exit_loop)],\n",
    "    )\n",
    "\n",
    "    refinement_loop_agent = LoopAgent(\n",
    "        name=f\"RefinementLoopAgent_{agent_id}\",\n",
    "        sub_agents=[\n",
    "            experience_critique_agent,\n",
    "            experience_refiner_agent,\n",
    "        ],\n",
    "        max_iterations=max_iterations,\n",
    "    )\n",
    "\n",
    "    experience_enhancement_sequence = SequentialAgent(\n",
    "        name=f\"ExperienceRefinementSequence_{agent_id}\",\n",
    "        sub_agents=[\n",
    "            initial_experience_draft_agent,\n",
    "            refinement_loop_agent,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return experience_enhancement_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a4a85",
   "metadata": {},
   "source": [
    "### 4. ðŸ“ Agent Chain Step: Experience Enhancement Orchestrator Agent (Parallel Execution)\n",
    "\n",
    "This custom agent is responsible for **orchestrating the parallel execution** of all individual experience enhancement agents.\n",
    "\n",
    "* **Parallelism (Architecture)**: It dynamically creates a `ParallelAgent` containing the specialized `ExperienceEnhancementAgent` for *each* retrieved experience. This significantly reduces total latency by running multiple LLM calls concurrently.\n",
    "* **Data Preparation**: It saves individual experience descriptions into the session state using unique keys (`experience_{agent_id}`) so that each parallel enhancement agent has access only to its required input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceEnhancementOrchestratorAgent(BaseAgent):\n",
    "    \"\"\"An agent that aggregates enhanced experiences from sub-agents.\"\"\"\n",
    "\n",
    "    max_refinement_iterations: int = 1\n",
    "\n",
    "    @t.override\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> t.AsyncGenerator[Event]:\n",
    "        logging.info(\n",
    "            f\"[{self.name}] Starting Experiences Enhancement Aggregator Agent.\"\n",
    "        )\n",
    "\n",
    "        retrived_exps: list[ExperienceRetrieval] = ctx.session.state.get(\n",
    "            \"retrieved_experiences\", []\n",
    "        )\n",
    "        if not retrived_exps:\n",
    "            logging.error(\n",
    "                f\"[{self.name}] No retrieved experiences found in session state.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Create a parallel agent to enhance each experience concurrently\n",
    "        tagged_experiences: dict[str, ExperienceRetrieval] = {}\n",
    "        parallel_sub_agents: list[SequentialAgent] = []\n",
    "        for exp in retrived_exps:\n",
    "            # We will tag each agent with the experience ID.\n",
    "            agent_id = exp[\"exp_id\"].replace(\".\", \"_\")\n",
    "\n",
    "            # Save the experience description in the session state,\n",
    "            #  to be used by the experience enhancement agents.\n",
    "            ctx.session.state[f\"experience_{agent_id}\"] = exp[\"description\"]\n",
    "\n",
    "            # Create an experience enhancement agent for each experience\n",
    "            enh_agent = experience_refinament_agent_factory(\n",
    "                exp_type=exp[\"exp_type\"],\n",
    "                agent_id=agent_id,\n",
    "                max_iterations=self.max_refinement_iterations,\n",
    "            )\n",
    "\n",
    "            # Finally, tag the experience for reference\n",
    "            tagged_experiences[agent_id] = exp\n",
    "            parallel_sub_agents.append(enh_agent)\n",
    "\n",
    "        parallel_enhancement_agent = ParallelAgent(\n",
    "            name=\"ParallelExperienceEnhancementAgent\",\n",
    "            sub_agents=parallel_sub_agents,\n",
    "        )\n",
    "\n",
    "        # Save tagged experiences in the session state for later reference\n",
    "        ctx.session.state[\"tagged_experiences\"] = tagged_experiences\n",
    "\n",
    "        # Run the parallel enhancement agent\n",
    "        async for event in parallel_enhancement_agent.run_async(ctx):\n",
    "            yield event\n",
    "\n",
    "\n",
    "experience_enhancement_orchestrator_agent = ExperienceEnhancementOrchestratorAgent(\n",
    "    name=\"ExperienceEnhancementOrchestratorAgent\",\n",
    "    max_refinement_iterations=MAX_REFINEMENT_ITERATIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac1455",
   "metadata": {},
   "source": [
    "### 5. ðŸ“ Agent Chain Step: Enhanced CV Assembly Agent (Final Output)\n",
    "\n",
    "The final agent in the sequence, responsible for aggregating the results of all preceding agents and compiling the final, enhanced CV document.\n",
    "\n",
    "* **Aggregation**: Gathers the final, structured enhanced content (`enhanced_experience_{agent_id}`) from the session state.\n",
    "* **Compilation**: Merges the unchanged basic CV data with the newly enhanced experience sections into a single, validated `JsonResume` object.\n",
    "* **Output**: Saves the final `enhanced_cv` object to the session state and outputs the JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from google.adk.agents import ParallelAgent\n",
    "\n",
    "\n",
    "class EnhancedCvAssemblyAgent(BaseAgent):\n",
    "    \"\"\"This agent enhances a CV based on the job offer summary and\n",
    "    retrieved experiences.\n",
    "    \"\"\"\n",
    "\n",
    "    json_resume_template: JsonResume\n",
    "\n",
    "    @t.override\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> t.AsyncGenerator[Event]:\n",
    "        logging.info(f\"[{self.name}] Starting CV Builder Agent.\")\n",
    "\n",
    "        # Get tagged experiences from the session state\n",
    "        tagged_experiences = t.cast(\n",
    "            dict[str, ExperienceRetrieval],\n",
    "            ctx.session.state.get(\"tagged_experiences\", {}),\n",
    "        )\n",
    "\n",
    "        # Get enhanced experiences from the session state\n",
    "        enhanced_experiences: dict[str, dict[str, t.Any]] = {}\n",
    "        for agent_id in tagged_experiences:\n",
    "            enhanced_exp = t.cast(\n",
    "                dict[str, t.Any],\n",
    "                ctx.session.state.get(f\"enhanced_experience_{agent_id}\"),\n",
    "            )\n",
    "            enhanced_experiences[agent_id] = enhanced_exp\n",
    "\n",
    "        # Build a json resume with the enhanced experiences\n",
    "        json_resume_enhanced: dict[str, dict | list] = {}\n",
    "\n",
    "        # Include basics from the template. It's assumed to be unchanged.\n",
    "        if basics := self.json_resume_template.basics:\n",
    "            json_resume_enhanced[\"basics\"] = basics.model_dump()\n",
    "\n",
    "        # Modify experiences with the enhanced versions\n",
    "        for agent_id, enhanced_exp in enhanced_experiences.items():\n",
    "            exp_id = tagged_experiences[agent_id][\"exp_id\"]\n",
    "            exp_type = tagged_experiences[agent_id][\"exp_type\"]\n",
    "            if exp_type not in json_resume_enhanced:\n",
    "                json_resume_enhanced[exp_type] = []\n",
    "\n",
    "            experience_obj = self.json_resume_template.find_experience(exp_id)\n",
    "            if experience_obj:\n",
    "                experience_dict = experience_obj.model_dump()\n",
    "                for field, value in enhanced_exp.items():\n",
    "                    experience_dict[field] = value\n",
    "                json_resume_enhanced[exp_type].append(experience_dict)  # type: ignore\n",
    "\n",
    "        enhanced_cv = JsonResume(**json_resume_enhanced)\n",
    "        ctx.session.state[\"enhanced_cv\"] = enhanced_cv\n",
    "\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            content={\"parts\": [{\"text\": enhanced_cv.model_dump_json(indent=2)}]},\n",
    "        )\n",
    "\n",
    "\n",
    "enhanced_cv_assembly_agent = EnhancedCvAssemblyAgent(\n",
    "    name=\"EnhancedCvAssemblyAgent\",\n",
    "    json_resume_template=get_json_resume(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66be95",
   "metadata": {},
   "source": [
    "### ðŸš€ Root Agent Orchestration (Main Pipeline)\n",
    "\n",
    "This cell defines the **Root Sequential Agent**, establishing the definitive, end-to-end flow of the entire CV enhancement process.\n",
    "\n",
    "* **Sequential Flow**: Clearly defines the order of operations, ensuring that the output of one agent (e.g., `job_offer_analyzer_agent`) becomes the necessary input for the next (e.g., `experience_query_builder_agent`).\n",
    "* **Architecture Review**: This definition confirms the overall solution architecture: **Sequential Agents for Pipeline Flow** + **Parallel Agents for Concurrent Processing** + **Loop Agents for Self-Correction/Refinement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import SequentialAgent\n",
    "\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"CvEnhancerFlowAgent\",\n",
    "    sub_agents=[\n",
    "        job_offer_analyzer_agent,\n",
    "        experience_query_builder_agent,\n",
    "        experience_retriever_agent,\n",
    "        experience_enhancement_orchestrator_agent,\n",
    "        enhanced_cv_assembly_agent,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d419b",
   "metadata": {},
   "source": [
    "## 4. ðŸ“ˆ Execution and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bb6d2",
   "metadata": {},
   "source": [
    "### ðŸƒ Runner Initialization and Logging\n",
    "\n",
    "This block initializes the `Runner`, which is the execution environment for the agent system, and sets up session management and logging.\n",
    "\n",
    "* **`InMemorySessionService`**: Used for managing the shared `session.state` across all agents in the pipeline (how data like `search_query` and `enhanced_experience` is passed).\n",
    "* **`LoggingPlugin`**: Ensures detailed tracking of the agent's internal reasoning, which is essential for debugging and performance analysis in a multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.plugins.logging_plugin import LoggingPlugin\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=\"cv_enhancer_app\",\n",
    "    session_service=session_service,\n",
    "    plugins=[\n",
    "        LoggingPlugin(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner created.\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949746fc",
   "metadata": {},
   "source": [
    "#### âœ… Execution and Final Result\n",
    "\n",
    "* **`runner.run_debug(JOB_OFFER_TEXT)`**: Executes the `CvEnhancerRootAgent` on the input job offer text. The `run_debug` method provides verbose output, crucial for understanding the flow and state changes in a complex multi-agent execution.\n",
    "* **Final Output**: Extracts and validates the enhanced CV from the final response, confirming that the entire pipeline successfully executed and produced a structured, enhanced `JsonResume` object ready for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await runner.run_debug(JOB_OFFER_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_response = response[-1]\n",
    "\n",
    "enhanced_cv = None\n",
    "if (content := last_response.content) and (parts := content.parts):\n",
    "    part = parts[0]\n",
    "    if cv_json := part.text:\n",
    "        enhanced_cv = JsonResume.model_validate_json(cv_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(enhanced_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-enhancer-gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
